# Configurazione SAC
policy: "MlpPolicy"
ent_coef: "auto" 
target_update_interval: 1   
target_entropy: "auto"      
gamma: 0.98                
tau: 0.02                 
seed: 42                   
device: "auto" 
action_noise: null
use_sde: True   
policy_kwargs: "dict(log_std_init=-3, net_arch=[1024, 1024])"

# Configurazione addestramento
learning_rate: "constant_0.00073"
learning_starts: 50_000  # quando iniziare apprendere la policy   
n_timesteps: 1_000_000 # numero totale di timesteps per l'addestramento
train_freq: 64
gradient_steps: 64

# Normalizzazioni
normalize_input: True
normalize_value: True # da rivere a seconda della variabilit√† delle ricompense 
batch_size: 512         
buffer_size: 2_000_000 
clip_obs: 10.0         